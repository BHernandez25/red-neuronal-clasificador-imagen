# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DiPjTptlMscToBIVahXAy1STzKNfd-ac
"""

import tensorflow as tf  
import tensorflow_datasets as tfds

datos, metadatos = tfds.load('fashion_mnist', as_supervised=True, with_info=True)

metadatos

datos_entrenamiento, datos_pruebas= datos['train'], datos['test']

nombres_clases = metadatos.features['label'].names

nombres_clases

#Normalizar los datos (pasar de 0-255 a 0-1)

def normalizar(imagenes, etiquetas):
  imagenes = tf.cast(imagenes, tf.float32)
  imagenes/=255 #aqui lo pasa de 0-255 a 0-1
  return imagenes,etiquetas


#Normalizar los datos de entrenamiento y pruebas con la funcion que se hizo
datos_entrenamiento = datos_entrenamiento.map(normalizar)
datos_pruebas = datos_pruebas.map(normalizar)

#Agregar a cache (usar memoria en lugar de disco, entramiento mas rapido)
datos_entrenamiento = datos_entrenamiento.cache()
datos_pruebas = datos_pruebas.cache()

#Mostrar una imagen de los datos de pruebas, de momento se muestra la primera 
for imagen, etiqueta in datos_entrenamiento.take(1):
  break
  imagen = imagen.numpy().reshape((28,28)) 
  
  import matplotlib.pyplot as plt

  plt.figure()
  plt.imshow(imagen, cmap=plt.cm.binary)
  plt.colorbar()
  plt.grid(False)
  plt.show()

plt.figure(figsize=(10,10))
for i, (imagen, etiqueta) in enumerate(datos_entrenamiento.take(25)):
  imagen= imagen.numpy().reshape((28,28))
  plt.subplot(5,5,i+1)
  plt.xticks([])
  plt.yticks([])
  plt.grid(False)
  plt.imshow(imagen, cmap=plt.cm.binary)
  plt.xlabel(nombres_clases[etiqueta])
  plt.show

#crear el modelo 

modelo = tf.keras.Sequential([
  tf.keras.layers.Flatten(input_shape=(28,28,1)), #1 blanco y negro    
  tf.keras.layers.Dense(50, activation=tf.nn.relu),
  tf.keras.layers.Dense(50, activation=tf.nn.relu),   
  tf.keras.layers.Dense(10, activation=tf.nn.softmax)#para redes de clasificacion                    
])

#Compilar el modelo

modelo.compile(
    optimizer='adam',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(),
    metrics=['accuracy']
)

num_ej_entrenamiento = metadatos.splits["train"].num_examples
num_ej_pruebas = metadatos.splits["test"].num_examples

print(num_ej_pruebas)
print(num_ej_entrenamiento)

TAMANO_LOTE=32

datos_entrenamiento = datos_entrenamiento.repeat().shuffle(num_ej_entrenamiento).batch(TAMANO_LOTE)
datos_pruebas = datos_pruebas.batch(TAMANO_LOTE)

import math
#Entrenar
historial = modelo.fit(datos_entrenamiento, epochs=5, steps_per_epoch= math.ceil(num_ej_entrenamiento/TAMANO_LOTE))

plt.xlabel("# Epoca")
plt.ylabel("Magnitud de perdida")
plt.plot(historial.history["loss"])

#Tomar cualquier indice del set de pruebas para ver su predicion 
imagen = imagenes_prueba[5]
imagen = np.array([imagen])
prediccion = modelo.predict(imagen)

print("Prediccion" + nombres_clases[np.argmax(prediccion[0])])